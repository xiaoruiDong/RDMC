{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db2d384",
   "metadata": {},
   "source": [
    "# Stable species conformer search\n",
    "Leverage ETKDG for stochastic conformer generation\n",
    "\n",
    "Use this as a base for ML conformer generation\n",
    "\n",
    "The idea is to have modular methods for each step, which are currently hardcoded. This includes:\n",
    "- initial conformer embedding (ETKDG, GeoMol)\n",
    "- optimization/energy (MMFF, UFF, GFN-FF, GFN2-xTB)\n",
    "- pruning (torsion fingerprints, CREGEN)\n",
    "- convergence metrics (conformational entropy/partition function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5cc41b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdmc import OpenBabelFF, RDKitFF, optimize_mol\n",
    "from rdmc.mol import RDKitMol\n",
    "from rdmc.view import mol_viewer, interactive_conformer_viewer\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "T = 298  # K\n",
    "R = 0.0019872  # kcal/(K*mol)\n",
    "HARTREE_TO_KCAL_MOL = 627.503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cd90b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import yaml\n",
    "import torch\n",
    "from geomol.model import GeoMol\n",
    "from geomol.featurization import featurize_mol_from_smiles\n",
    "from torch_geometric.data import Batch\n",
    "from geomol.inference import construct_conformers\n",
    "\n",
    "class GeoMolEmbedder:\n",
    "    def __init__(self, trained_model_dir):\n",
    "        \n",
    "        # TODO: add option of pre-pruning geometries using alpha values\n",
    "        # TODO: add option of changing \"temperature\" each iteration to sample diverse geometries\n",
    "        \n",
    "        with open(osp.join(trained_model_dir, \"model_parameters.yml\")) as f:\n",
    "            model_parameters = yaml.full_load(f)\n",
    "        model = GeoMol(**model_parameters)\n",
    "\n",
    "        state_dict = torch.load(osp.join(trained_model_dir, \"best_model.pt\"), map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        model.eval()\n",
    "        self.model = model\n",
    "        self.tg_data = None\n",
    "        \n",
    "    def __call__(self, smiles, n_conformers, std=1.0):\n",
    "\n",
    "        # set \"temperature\"\n",
    "        self.model.random_vec_std = std\n",
    "\n",
    "        # featurize data and run GeoMol\n",
    "        if self.tg_data is None:\n",
    "            self.tg_data = featurize_mol_from_smiles(smiles, dataset=\"drugs\")\n",
    "        data = Batch.from_data_list([self.tg_data])  # need to run this bc of dumb internal GeoMol processing\n",
    "        self.model(data, inference=True, n_model_confs=n_conformers)\n",
    "\n",
    "        # process predictions\n",
    "        n_atoms = self.tg_data.x.size(0)\n",
    "        model_coords = construct_conformers(data, self.model).double().cpu().detach().numpy()\n",
    "        split_model_coords = np.split(model_coords, n_conformers, axis=1)\n",
    "\n",
    "        # package in mol and return\n",
    "        mol = RDKitMol.FromSmiles(smiles)\n",
    "        mol.EmbedMultipleNullConfs(n=n_conformers)\n",
    "        [mol.SetPositions(coords=x.squeeze(axis=1), id=i) for i, x in enumerate(split_model_coords)]\n",
    "\n",
    "        return mol\n",
    "    \n",
    "    \n",
    "class ETKDGEmbedder:\n",
    "    def __init__(self):\n",
    "        self.mol = None\n",
    "        \n",
    "    def __call__(self, smiles, n_conformers):\n",
    "        if self.mol is None:\n",
    "            self.mol = RDKitMol.FromSmiles(smiles)\n",
    "            \n",
    "        mol = self.mol.Copy()    \n",
    "        mol.EmbedMultipleConfs(n_conformers)\n",
    "        return mol\n",
    "    \n",
    "    \n",
    "class RandomEmbedder:\n",
    "    def __init__(self):\n",
    "        self.mol = None\n",
    "        \n",
    "    def __call__(self, smiles, n_conformers):\n",
    "        if self.mol is None:\n",
    "            self.mol = RDKitMol.FromSmiles(smiles)\n",
    "            \n",
    "        mol = self.mol.Copy()    \n",
    "        mol.EmbedMultipleNullConfs(n_conformers)\n",
    "        return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e379f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMFFOptimizer:\n",
    "    def __init__(self, method=\"rdkit\"):\n",
    "        if method == \"rdkit\":\n",
    "            self.ff = RDKitFF()\n",
    "        elif method == \"openbabel\":\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    def __call__(self, mol):\n",
    "        \n",
    "        self.ff.setup(mol.Copy())\n",
    "        results = self.ff.optimize_confs()\n",
    "        _, energies = zip(*results)  # kcal/mol\n",
    "        opt_mol = self.ff.get_optimized_mol()\n",
    "        \n",
    "        current_mol_data = []\n",
    "        for c_id, energy in zip(range(opt_mol.GetNumConformers()), energies):\n",
    "            conf = copy.copy(opt_mol.GetConformer(c_id))\n",
    "            positions = conf.GetPositions()\n",
    "            current_mol_data.append({\"positions\": positions,\n",
    "                                     \"conf\": conf,\n",
    "                                     \"energy\": energy})\n",
    "        return current_mol_data\n",
    "    \n",
    "    \n",
    "class XTBOptimizer:\n",
    "    def __init__(self, method=\"gff\"):\n",
    "        self.method = method\n",
    "    \n",
    "    def __call__(self, mol):\n",
    "        \n",
    "        new_mol = mol.Copy()\n",
    "        new_mol._mol.RemoveAllConformers()\n",
    "        new_mol.EmbedNullConformer()\n",
    "        conformers = mol.GetAllConformers()\n",
    "        \n",
    "        current_mol_data = []\n",
    "        for c_id, c in enumerate(conformers):\n",
    "            pos = c.GetPositions()\n",
    "            new_mol.SetPositions(pos)\n",
    "            try:\n",
    "                _, opt_mol = run_xtb_calc(new_mol, opt=True, return_optmol=True, method=self.method)\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            \n",
    "            conf = opt_mol.Copy().GetConformer(0)\n",
    "            positions = conf.GetPositions()\n",
    "            energy = float(opt_mol.GetProp('total energy / Eh')) * HARTREE_TO_KCAL_MOL  # kcal/mol (TODO: check)\n",
    "            current_mol_data.append({\"positions\": positions,\n",
    "                                     \"conf\": conf,\n",
    "                                     \"energy\": energy})\n",
    "\n",
    "        return current_mol_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eba6dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCGMetric:\n",
    "    def __init__(self, metric=\"entropy\", window=5, threshold=0.01, T=298):\n",
    "        self.metric = metric\n",
    "        self.window = window\n",
    "        self.threshold = threshold\n",
    "        self.T = T\n",
    "        self.metric_history = []\n",
    "        \n",
    "    def calculate_metric(self, mol_data):\n",
    "        \n",
    "        if self.metric == \"entropy\":\n",
    "            metric_val = self.calculate_entropy(mol_data)\n",
    "        \n",
    "        elif self.metric == \"partition function\":\n",
    "            metric_val = self.calculate_partition_function(mol_data)\n",
    "            \n",
    "        else:\n",
    "            raise NotImplementedError(f\"Metric {self.metric} is not supported.\")\n",
    "            \n",
    "        self.metric_history.append(metric_val)\n",
    "        \n",
    "        \n",
    "    def check_metric(self):\n",
    "        \n",
    "        min_metric = np.min(self.metric_history[-self.window:])\n",
    "        max_metric = np.max(self.metric_history[-self.window:])\n",
    "        change = (max_metric-min_metric)/min_metric\n",
    "        return True if change <= self.threshold else False\n",
    "        \n",
    "        \n",
    "    def calculate_entropy(self, mol_data):\n",
    "        \n",
    "        energies = np.array([c[\"energy\"] for c in mol_data])\n",
    "        energies = energies-energies.min()\n",
    "        _prob = np.exp(-energies / (R*self.T))\n",
    "        prob = _prob / _prob.sum()\n",
    "        entropy = -R * np.sum(prob * np.log(prob))\n",
    "        return entropy\n",
    "    \n",
    "    \n",
    "    def calculate_partition_function(self, mol_data):\n",
    "        \n",
    "        energies = np.array([c[\"energy\"] for c in mol_data])\n",
    "        energies = energies-energies.min()\n",
    "        prob = np.exp(-energies / (R*self.T))\n",
    "        partition_fn = 1 + prob.sum()\n",
    "        return partition_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a49deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_angle_compare = lambda x,y: np.abs(np.arctan2(np.sin(x-y), np.cos(x-y))) * 180 / np.pi\n",
    "torsion_list_compare = lambda c1_ts, c2_ts: [rad_angle_compare(t1, t2) for t1, t2 in zip(c1_ts, c2_ts)]\n",
    "\n",
    "class TorsionPruner:\n",
    "    \"\"\"\n",
    "    Prune conformers based on torsion angle criteria.\n",
    "    This method uses a mean and max criteria to prune conformers:\n",
    "    A conformer is considered unique if it satisfies either of the following criteria:\n",
    "        mean difference of all torsion angles > mean_chk_threshold\n",
    "        max difference of all torsion angles > max_chk_threshold\n",
    "    New conformers are compared to all conformers that have already been deemed unique\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mean_chk_threshold=10, max_chk_threshold=20):\n",
    "        \n",
    "        self.mean_chk_threshold = mean_chk_threshold\n",
    "        self.max_chk_threshold = max_chk_threshold\n",
    "        self.torsions_list = None\n",
    "        \n",
    "    def initialize_torsions_list(self, smiles):\n",
    "        \n",
    "        mol = RDKitMol.FromSmiles(smiles)\n",
    "        mol.EmbedNullConformer()\n",
    "        self.torsions_list = mol.GetConformer().GetTorsionalModes()\n",
    "        \n",
    "    def calculate_torsions(self, mol_data):\n",
    "            \n",
    "        for conf_data in mol_data:\n",
    "            conf = conf_data[\"conf\"]\n",
    "            torsions = np.array([conf.GetTorsionDeg(t) for t in self.torsions_list]) % 360\n",
    "            conf_data.update({\"torsions\": torsions})\n",
    "        return mol_data\n",
    "        \n",
    "    def __call__(self, current_mol_data, unique_mol_data):\n",
    "        \n",
    "        # calculate torsions for new mols\n",
    "        current_mol_data = self.calculate_torsions(current_mol_data)\n",
    "        \n",
    "        # prep comparison and compute torsion matrix\n",
    "        n_unique_mols = max(1, len(unique_mol_data))  # set to 1 if 0\n",
    "        mols_list = unique_mol_data + current_mol_data\n",
    "        torsion_matrix = np.stack([c[\"torsions\"] for c in mols_list])\n",
    "        torsion_matrix_rad = torsion_matrix * np.pi / 180\n",
    "        n_confs = len(mols_list)\n",
    "        conf_ids = np.arange(n_confs).tolist()\n",
    "        \n",
    "        # start comparison at new mols\n",
    "        for i in conf_ids[n_unique_mols:]:\n",
    "\n",
    "            c_torsions = torsion_matrix_rad[i]  # torsions of this conformer\n",
    "            c_before_torsions = torsion_matrix_rad[:i]  # torsions of all other conformers already compared\n",
    "\n",
    "            # mean and max criteria checks\n",
    "            comp = np.array([torsion_list_compare(c_torsions, ct) for ct in c_before_torsions])\n",
    "            chk1 = (np.mean(comp, axis=1) < self.mean_chk_threshold).any()\n",
    "            chk2 = (np.max(comp, axis=1) < self.max_chk_threshold).any()\n",
    "            \n",
    "            # remove conformer if either check is satisfied\n",
    "            if chk1 or chk2:\n",
    "                conf_ids.remove(i)\n",
    "        \n",
    "        # update mols and sort by energy\n",
    "        updated_unique_mol_data = sorted([mols_list[i] for i in conf_ids], key=lambda x: x[\"energy\"])\n",
    "        return updated_unique_mol_data\n",
    "    \n",
    "    \n",
    "class CRESTPruner:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, current_mol_data, unique_mol_data):\n",
    "        \n",
    "        print(\"current:\", len(unique_mol_data), \"new:\", len(current_mol_data))\n",
    "        all_mol_data = unique_mol_data + current_mol_data\n",
    "        updated_unique_mol_data = run_cre_check(all_mol_data)\n",
    "        updated_unique_mol_data = sorted(updated_unique_mol_data, key=lambda x: x[\"energy\"])\n",
    "        return updated_unique_mol_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe7fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cfbc04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticConformerGenerator:\n",
    "    def __init__(self, smiles, conformer_embedder, optimizer, pruner,\n",
    "                 metric, min_iters=5, max_iters=10, optimize=True):\n",
    "        super(StochasticConformerGenerator, self).__init__()\n",
    "\n",
    "        self.smiles = smiles\n",
    "        self.conformer_embedder = conformer_embedder\n",
    "        self.optimizer = optimizer\n",
    "        self.pruner = pruner\n",
    "        self.metric = metric\n",
    "        \n",
    "        self.mol = RDKitMol.FromSmiles(smiles)\n",
    "        self.unique_mol_data = []\n",
    "        self.iter = 0\n",
    "        self.min_iters = min_iters\n",
    "        self.max_iters = max_iters\n",
    "        self.optimize = optimize\n",
    "        \n",
    "        if isinstance(self.pruner, TorsionPruner):\n",
    "            self.pruner.initialize_torsions_list(smiles)\n",
    "\n",
    "    def calculate_energy(self, mol, unique_mols):\n",
    "        \n",
    "        # TODO: figure out what to do w this (only used if optimize is set to False)\n",
    "        ff = RDKitFF()\n",
    "        for c in unique_mols:\n",
    "            if np.isnan(c[\"energy\"]):\n",
    "                ff.setup(mol.Copy(), conf_id=c[\"conf_id\"])  # TODO: fix this bc not using conf_id anymore\n",
    "                energy = ff.get_energy()\n",
    "                c.update({\"energy\": energy})  # kJ\n",
    "\n",
    "        return unique_mols\n",
    "    \n",
    "    def __call__(self, n_conformers_per_iter):\n",
    "        \n",
    "        print(f\"Generating conformers for {self.smiles}\")\n",
    "        for it in range(self.max_iters):\n",
    "            self.iter += 1\n",
    "            \n",
    "            print(f\"\\nIteration {self.iter}: embedding {n_conformers_per_iter} initial guesses...\")\n",
    "            initial_mol = self.conformer_embedder(self.smiles, n_conformers_per_iter)\n",
    "            \n",
    "            if self.optimize:\n",
    "                print(f\"Iteration {self.iter}: optimizing initial guesses...\")\n",
    "                opt_mol_data = self.optimizer(initial_mol)\n",
    "            else:\n",
    "                # TODO\n",
    "                opt_mol_data = []\n",
    "                for c_id in range(initial_mol.GetNumConformers()):\n",
    "                    conf = copy.copy(initial_mol.GetConformer(c_id))\n",
    "                    positions = conf.GetPositions()\n",
    "                    opt_mol_data.append({\"positions\": positions,\n",
    "                                         \"conf\": conf,\n",
    "                                         \"energy\": np.nan})\n",
    "                opt_mol_data = self.calculate_energy(initial_mol, opt_mol_data)\n",
    "                \n",
    "            # check for failures\n",
    "            if len(opt_mol_data) == 0:\n",
    "                print(\"Failed to optimize any of the embedded conformers\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Iteration {self.iter}: pruning conformers...\")\n",
    "            unique_mol_data = self.pruner(opt_mol_data, self.unique_mol_data)\n",
    "            self.metric.calculate_metric(unique_mol_data)\n",
    "            self.unique_mol_data = unique_mol_data\n",
    "            \n",
    "            if it < self.min_iters:\n",
    "                continue\n",
    "                \n",
    "            if self.metric.check_metric():\n",
    "                print(f\"Iteration {self.iter}: stop crietria reached\")\n",
    "                return unique_mol_data\n",
    "            \n",
    "        print(f\"Iteration {self.iter}: max iterations reached\")\n",
    "        return unique_mol_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99efe85f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating conformers for c1ccccc1\n",
      "\n",
      "Iteration 1: embedding 50 initial guesses...\n",
      "Iteration 1: optimizing initial guesses...\n",
      "Iteration 1: pruning conformers...\n",
      "current: 0 new: 50\n",
      "Removed 46 duplicate conformers with cregen\n",
      "\n",
      "Iteration 2: embedding 50 initial guesses...\n",
      "Iteration 2: optimizing initial guesses...\n",
      "Iteration 2: pruning conformers...\n",
      "current: 4 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 3: embedding 50 initial guesses...\n",
      "Iteration 3: optimizing initial guesses...\n",
      "Iteration 3: pruning conformers...\n",
      "current: 5 new: 50\n",
      "Removed 46 duplicate conformers with cregen\n",
      "\n",
      "Iteration 4: embedding 50 initial guesses...\n",
      "Iteration 4: optimizing initial guesses...\n",
      "Iteration 4: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 53 duplicate conformers with cregen\n",
      "\n",
      "Iteration 5: embedding 50 initial guesses...\n",
      "Iteration 5: optimizing initial guesses...\n",
      "Iteration 5: pruning conformers...\n",
      "current: 6 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 6: embedding 50 initial guesses...\n",
      "Iteration 6: optimizing initial guesses...\n",
      "Iteration 6: pruning conformers...\n",
      "current: 7 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 7: embedding 50 initial guesses...\n",
      "Iteration 7: optimizing initial guesses...\n",
      "Iteration 7: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 51 duplicate conformers with cregen\n",
      "\n",
      "Iteration 8: embedding 50 initial guesses...\n",
      "Iteration 8: optimizing initial guesses...\n",
      "Iteration 8: pruning conformers...\n",
      "current: 7 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 9: embedding 50 initial guesses...\n",
      "Iteration 9: optimizing initial guesses...\n",
      "Iteration 9: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 10: embedding 50 initial guesses...\n",
      "Iteration 10: optimizing initial guesses...\n",
      "Iteration 10: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 54 duplicate conformers with cregen\n",
      "\n",
      "Iteration 11: embedding 50 initial guesses...\n",
      "Iteration 11: optimizing initial guesses...\n",
      "Iteration 11: pruning conformers...\n",
      "current: 5 new: 50\n",
      "Removed 46 duplicate conformers with cregen\n",
      "\n",
      "Iteration 12: embedding 50 initial guesses...\n",
      "Iteration 12: optimizing initial guesses...\n",
      "Iteration 12: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 51 duplicate conformers with cregen\n",
      "\n",
      "Iteration 13: embedding 50 initial guesses...\n",
      "Iteration 13: optimizing initial guesses...\n",
      "Iteration 13: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 46 duplicate conformers with cregen\n",
      "\n",
      "Iteration 14: embedding 50 initial guesses...\n",
      "Iteration 14: optimizing initial guesses...\n",
      "Iteration 14: pruning conformers...\n",
      "current: 12 new: 50\n",
      "Removed 53 duplicate conformers with cregen\n",
      "\n",
      "Iteration 15: embedding 50 initial guesses...\n",
      "Iteration 15: optimizing initial guesses...\n",
      "Iteration 15: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 50 duplicate conformers with cregen\n",
      "\n",
      "Iteration 16: embedding 50 initial guesses...\n",
      "Iteration 16: optimizing initial guesses...\n",
      "Iteration 16: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 51 duplicate conformers with cregen\n",
      "\n",
      "Iteration 17: embedding 50 initial guesses...\n",
      "Iteration 17: optimizing initial guesses...\n",
      "Iteration 17: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 48 duplicate conformers with cregen\n",
      "\n",
      "Iteration 18: embedding 50 initial guesses...\n",
      "Iteration 18: optimizing initial guesses...\n",
      "Iteration 18: pruning conformers...\n",
      "current: 10 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 19: embedding 50 initial guesses...\n",
      "Iteration 19: optimizing initial guesses...\n",
      "Iteration 19: pruning conformers...\n",
      "current: 11 new: 50\n",
      "Removed 54 duplicate conformers with cregen\n",
      "\n",
      "Iteration 20: embedding 50 initial guesses...\n",
      "Iteration 20: optimizing initial guesses...\n",
      "Iteration 20: pruning conformers...\n",
      "current: 7 new: 50\n",
      "Removed 50 duplicate conformers with cregen\n",
      "\n",
      "Iteration 21: embedding 50 initial guesses...\n",
      "Iteration 21: optimizing initial guesses...\n",
      "Iteration 21: pruning conformers...\n",
      "current: 7 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 22: embedding 50 initial guesses...\n",
      "Iteration 22: optimizing initial guesses...\n",
      "Iteration 22: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 23: embedding 50 initial guesses...\n",
      "Iteration 23: optimizing initial guesses...\n",
      "Iteration 23: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 51 duplicate conformers with cregen\n",
      "\n",
      "Iteration 24: embedding 50 initial guesses...\n",
      "Iteration 24: optimizing initial guesses...\n",
      "Iteration 24: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 25: embedding 50 initial guesses...\n",
      "Iteration 25: optimizing initial guesses...\n",
      "Iteration 25: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 52 duplicate conformers with cregen\n",
      "\n",
      "Iteration 26: embedding 50 initial guesses...\n",
      "Iteration 26: optimizing initial guesses...\n",
      "Iteration 26: pruning conformers...\n",
      "current: 7 new: 50\n",
      "Removed 45 duplicate conformers with cregen\n",
      "\n",
      "Iteration 27: embedding 50 initial guesses...\n",
      "Iteration 27: optimizing initial guesses...\n",
      "Iteration 27: pruning conformers...\n",
      "current: 12 new: 50\n",
      "Removed 52 duplicate conformers with cregen\n",
      "\n",
      "Iteration 28: embedding 50 initial guesses...\n",
      "Iteration 28: optimizing initial guesses...\n",
      "Iteration 28: pruning conformers...\n",
      "current: 10 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 29: embedding 50 initial guesses...\n",
      "Iteration 29: optimizing initial guesses...\n",
      "Iteration 29: pruning conformers...\n",
      "current: 11 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 30: embedding 50 initial guesses...\n",
      "Iteration 30: optimizing initial guesses...\n",
      "Iteration 30: pruning conformers...\n",
      "current: 12 new: 50\n",
      "Removed 54 duplicate conformers with cregen\n",
      "\n",
      "Iteration 31: embedding 50 initial guesses...\n",
      "Iteration 31: optimizing initial guesses...\n",
      "Iteration 31: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 48 duplicate conformers with cregen\n",
      "\n",
      "Iteration 32: embedding 50 initial guesses...\n",
      "Iteration 32: optimizing initial guesses...\n",
      "Iteration 32: pruning conformers...\n",
      "current: 10 new: 50\n",
      "Removed 52 duplicate conformers with cregen\n",
      "\n",
      "Iteration 33: embedding 50 initial guesses...\n",
      "Iteration 33: optimizing initial guesses...\n",
      "Iteration 33: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 47 duplicate conformers with cregen\n",
      "\n",
      "Iteration 34: embedding 50 initial guesses...\n",
      "Iteration 34: optimizing initial guesses...\n",
      "Iteration 34: pruning conformers...\n",
      "current: 11 new: 50\n",
      "Removed 53 duplicate conformers with cregen\n",
      "\n",
      "Iteration 35: embedding 50 initial guesses...\n",
      "Iteration 35: optimizing initial guesses...\n",
      "Iteration 35: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 48 duplicate conformers with cregen\n",
      "\n",
      "Iteration 36: embedding 50 initial guesses...\n",
      "Iteration 36: optimizing initial guesses...\n",
      "Iteration 36: pruning conformers...\n",
      "current: 10 new: 50\n",
      "Removed 51 duplicate conformers with cregen\n",
      "\n",
      "Iteration 37: embedding 50 initial guesses...\n",
      "Iteration 37: optimizing initial guesses...\n",
      "Iteration 37: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 47 duplicate conformers with cregen\n",
      "\n",
      "Iteration 38: embedding 50 initial guesses...\n",
      "Iteration 38: optimizing initial guesses...\n",
      "Iteration 38: pruning conformers...\n",
      "current: 12 new: 50\n",
      "Removed 57 duplicate conformers with cregen\n",
      "\n",
      "Iteration 39: embedding 50 initial guesses...\n",
      "Iteration 39: optimizing initial guesses...\n",
      "Iteration 39: pruning conformers...\n",
      "current: 5 new: 50\n",
      "Removed 45 duplicate conformers with cregen\n",
      "\n",
      "Iteration 40: embedding 50 initial guesses...\n",
      "Iteration 40: optimizing initial guesses...\n",
      "Iteration 40: pruning conformers...\n",
      "current: 10 new: 50\n",
      "Removed 51 duplicate conformers with cregen\n",
      "\n",
      "Iteration 41: embedding 50 initial guesses...\n",
      "Iteration 41: optimizing initial guesses...\n",
      "Iteration 41: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 50 duplicate conformers with cregen\n",
      "\n",
      "Iteration 42: embedding 50 initial guesses...\n",
      "Iteration 42: optimizing initial guesses...\n",
      "Iteration 42: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 51 duplicate conformers with cregen\n",
      "\n",
      "Iteration 43: embedding 50 initial guesses...\n",
      "Iteration 43: optimizing initial guesses...\n",
      "Iteration 43: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 48 duplicate conformers with cregen\n",
      "\n",
      "Iteration 44: embedding 50 initial guesses...\n",
      "Iteration 44: optimizing initial guesses...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44: pruning conformers...\n",
      "current: 10 new: 50\n",
      "Removed 52 duplicate conformers with cregen\n",
      "\n",
      "Iteration 45: embedding 50 initial guesses...\n",
      "Iteration 45: optimizing initial guesses...\n",
      "Iteration 45: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 50 duplicate conformers with cregen\n",
      "\n",
      "Iteration 46: embedding 50 initial guesses...\n",
      "Iteration 46: optimizing initial guesses...\n",
      "Iteration 46: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 47: embedding 50 initial guesses...\n",
      "Iteration 47: optimizing initial guesses...\n",
      "Iteration 47: pruning conformers...\n",
      "current: 9 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 48: embedding 50 initial guesses...\n",
      "Iteration 48: optimizing initial guesses...\n",
      "Iteration 48: pruning conformers...\n",
      "current: 10 new: 50\n",
      "Removed 49 duplicate conformers with cregen\n",
      "\n",
      "Iteration 49: embedding 50 initial guesses...\n",
      "Iteration 49: optimizing initial guesses...\n",
      "Iteration 49: pruning conformers...\n",
      "current: 11 new: 50\n",
      "Removed 53 duplicate conformers with cregen\n",
      "\n",
      "Iteration 50: embedding 50 initial guesses...\n",
      "Iteration 50: optimizing initial guesses...\n",
      "Iteration 50: pruning conformers...\n",
      "current: 8 new: 50\n",
      "Removed 47 duplicate conformers with cregen\n",
      "\n",
      "Iteration 51: embedding 50 initial guesses...\n",
      "Iteration 51: optimizing initial guesses...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2591/3986870249.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[0mn_conformers_per_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0munique_conformers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_conformers_per_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_conformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2591/2720498409.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, n_conformers_per_iter)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Iteration {self.iter}: optimizing initial guesses...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mopt_mol_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_mol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2591/589473858.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, mol)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mnew_mol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetPositions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_mol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_xtb_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_optmol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2591/2905343855.py\u001b[0m in \u001b[0;36mrun_xtb_calc\u001b[0;34m(mol, opt, return_optmol, method)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTDOUT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXTB_ENV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxtb_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GeoMol/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GeoMol/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GeoMol/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0merrpipe_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m                     \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m                     \u001b[0merrpipe_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# conformer_embedder = RandomEmbedder()\n",
    "# conformer_embedder = ETKDGEmbedder()\n",
    "conformer_embedder = GeoMolEmbedder(\"../../GeoMol/trained_models/drugs/\")\n",
    "\n",
    "# optimizer = MMFFOptimizer()\n",
    "optimizer = XTBOptimizer(method=\"gff\")\n",
    "\n",
    "# pruner = TorsionPruner(mean_chk_threshold=10, max_chk_threshold=20)\n",
    "pruner = CRESTPruner()\n",
    "\n",
    "metric = SCGMetric(metric=\"entropy\", window=5, threshold=0.01)\n",
    "\n",
    "# O=C(/C=C/c1ccco1)Nc1ccc(Cl)c(S(=O)(=O)N2CCOCC2)c1\n",
    "scg = StochasticConformerGenerator(\n",
    "    smiles=\"c1ccccc1\",\n",
    "    conformer_embedder=conformer_embedder,\n",
    "    optimizer=optimizer,\n",
    "    pruner=pruner,\n",
    "    metric=metric,\n",
    "    max_iters=100,\n",
    "    optimize=True\n",
    ")\n",
    "n_conformers_per_iter = 50\n",
    "unique_conformers = scg(n_conformers_per_iter)\n",
    "print(len(unique_conformers), scg.metric.metric_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1910f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "047ba951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050fa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "525ddeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mol = scg.mol.Copy()\n",
    "[final_mol._mol.AddConformer(c[\"conf\"].ToConformer(), assignId=True) for c in scg.unique_mol_data];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c8e5bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082e40df5be04f2e91aaca36552c2aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='confId', max=10), Output()), _dom_classes=('widget-interâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function rdmc.view.interactive_conformer_viewer.<locals>.<lambda>(confId)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_conformer_viewer(final_mol, viewer_size=(800, 800), atom_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea5d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e680e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREST_BINARY = os.path.join(os.environ.get(\"CONDA_PREFIX\"), \"bin\", \"crest\")\n",
    "\n",
    "def make_xyz_text(rd_mol,\n",
    "                  comment):\n",
    "\n",
    "    atoms = [i for i in rd_mol.GetAtoms()]\n",
    "    num_atoms = len(atoms)\n",
    "    pos = rd_mol.GetConformers()[0].GetPositions()\n",
    "\n",
    "    lines = [str(num_atoms), comment]\n",
    "\n",
    "    for atom, this_pos in zip(atoms, pos):\n",
    "        line = \"%s %.8f %.8f %.8f \" % (atom.GetSymbol(),\n",
    "                                       this_pos[0], this_pos[1], this_pos[2])\n",
    "        lines.append(line)\n",
    "\n",
    "    text = \"\\n\".join(lines)\n",
    "    return text\n",
    "\n",
    "\n",
    "def write_confs_xyz(confs, path):\n",
    "\n",
    "    text = \"\"\n",
    "    for i, conf in enumerate(confs):\n",
    "        rd_mol = conf[\"conf\"].GetOwningMol()\n",
    "        energy = conf['energy']\n",
    "        comment = \"%.8f !CONF%d\" % (energy, i + 1)\n",
    "\n",
    "        this_text = make_xyz_text(rd_mol=rd_mol,\n",
    "                                  comment=comment)\n",
    "\n",
    "        if i != 0:\n",
    "            text += \"\\n\"\n",
    "        text += this_text\n",
    "\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(text)\n",
    "\n",
    "\n",
    "def read_unique(job_dir):\n",
    "    path = os.path.join(job_dir, \"enso.tags\")\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    unique_idx = []\n",
    "    for line in lines:\n",
    "        split = line.strip().split()\n",
    "        if not split:\n",
    "            continue\n",
    "\n",
    "        idx = split[-1].split(\"!CONF\")[-1]\n",
    "        # means something went wrong\n",
    "        if not idx.isdigit():\n",
    "            return\n",
    "\n",
    "        unique_idx.append(int(idx) - 1)\n",
    "\n",
    "    return unique_idx\n",
    "\n",
    "        \n",
    "def run_cre_check(confs):\n",
    "\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "    logfile = os.path.join(temp_dir, \"xtb.log\")\n",
    "    confs_path = os.path.join(temp_dir, \"confs.xyz\")\n",
    "    conf_0_path = os.path.join(temp_dir, \"conf_0.xyz\")\n",
    "    cregen_out = os.path.join(temp_dir, \"cregen.out\")\n",
    "\n",
    "    write_confs_xyz(confs, path=confs_path)\n",
    "    write_confs_xyz(confs[:1], path=conf_0_path)\n",
    "\n",
    "    with open(logfile, \"w\") as f:\n",
    "        xtb_run = subprocess.run(\n",
    "                    [\n",
    "                        CREST_BINARY,\n",
    "                        conf_0_path,\n",
    "                        \"--cregen\",\n",
    "                        confs_path,\n",
    "                        \"--ethr\", \"0.05\", \"--rthr\", \"0.125\", \"--bthr\", \"0.01\", \"--ewin\", \"10000\", \"--enso\",\n",
    "                        \">\",\n",
    "                        cregen_out,\n",
    "                    ],\n",
    "                    stdout=f,\n",
    "                    stderr=subprocess.STDOUT,\n",
    "                    cwd=temp_dir,\n",
    "                    env=XTB_ENV,\n",
    "                )\n",
    "\n",
    "    if xtb_run.returncode != 0:\n",
    "        error_out = os.path.join(temp_dir, \"xtb.log\")\n",
    "        raise ValueError(f\"xTB calculation failed. See {error_out} for details.\")\n",
    "\n",
    "    unique_ids = read_unique(temp_dir)\n",
    "    updated_confs = [confs[i] for i in unique_ids]\n",
    "    #rmtree(temp_dir)\n",
    "    \n",
    "    ### DEBUG ###\n",
    "    # num_removed = len(confs) - len(unique_ids)\n",
    "    # plural = 's' if num_removed > 1 else ''\n",
    "    # print(\"Removed %d duplicate conformer%s with cregen\" % (num_removed, plural))\n",
    "    ### DEBUG ###\n",
    "\n",
    "    return updated_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17d3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from shutil import rmtree\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "from openbabel import pybel\n",
    "\n",
    "from rdmc.external.xtb.utils import (\n",
    "    ATOM_ENERGIES_XTB,\n",
    "    ATOMNUM_TO_ELEM,\n",
    "    AU_TO_DEBYE,\n",
    "    EV_TO_HARTREE,\n",
    "    UTILS_PATH,\n",
    "    XTB_BINARY,\n",
    ")\n",
    "\n",
    "XTB_INPUT_FILE = os.path.join(UTILS_PATH, \"xtb.inp\")\n",
    "XTB_ENV = {\n",
    "    \"OMP_STACKSIZE\": \"1G\",\n",
    "    \"OMP_NUM_THREADS\": \"1\",\n",
    "    \"OMP_MAX_ACTIVE_LEVELS\": \"1\",\n",
    "    \"MKL_NUM_THREADS\": \"1\",\n",
    "}\n",
    "\n",
    "\n",
    "def read_xtb_json(json_file, mol):\n",
    "    \"\"\"Reads JSON output file from xTB.\n",
    "    Parameters\n",
    "    ----------\n",
    "    json_file : str\n",
    "        path to output file\n",
    "    mol : pybel molecule object\n",
    "        molecule object, needed to compute atomic energy\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        dictionary of xTB properties\n",
    "    \"\"\"\n",
    "\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    E_homo, E_lumo = get_homo_and_lumo_energies(data)\n",
    "    atoms = [ATOMNUM_TO_ELEM[atom.GetAtomicNum()] for atom in mol.GetAtoms()]\n",
    "    atomic_energy = sum([ATOM_ENERGIES_XTB[atom] for atom in atoms])\n",
    "    props = {\n",
    "        \"E_form\": data[\"total energy\"] - atomic_energy,  # already in Hartree\n",
    "        \"E_homo\": E_homo * EV_TO_HARTREE,\n",
    "        \"E_lumo\": E_lumo * EV_TO_HARTREE,\n",
    "        \"E_gap\": data[\"HOMO-LUMO gap/eV\"] * EV_TO_HARTREE,\n",
    "        \"dipole\": np.linalg.norm(data[\"dipole\"]) * AU_TO_DEBYE,\n",
    "        \"charges\": data[\"partial charges\"],\n",
    "    }\n",
    "    return props\n",
    "\n",
    "\n",
    "def get_homo_and_lumo_energies(data):\n",
    "    \"\"\"Extracts HOMO and LUMO energies.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dict\n",
    "        dictionary from xTB JSON output\n",
    "    Returns\n",
    "    -------\n",
    "    tuple(float)\n",
    "        HOMO/LUMO energies in eV\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        in case of unpaired electrons (not supported)\n",
    "    \"\"\"\n",
    "    if data[\"number of unpaired electrons\"] != 0:\n",
    "        raise ValueError(\"Unpaired electrons are not supported.\")\n",
    "    num_occupied = (\n",
    "        np.array(data[\"fractional occupation\"]) > 1e-6\n",
    "    ).sum()  # number of occupied orbitals; accounting for occassional very small values\n",
    "    E_homo = data[\"orbital energies/eV\"][num_occupied - 1]  # zero-indexing\n",
    "    E_lumo = data[\"orbital energies/eV\"][num_occupied]\n",
    "    return E_homo, E_lumo\n",
    "\n",
    "\n",
    "def get_wbo(wbo_file):\n",
    "    \"\"\"Reads WBO output file from xTB and generates a dictionary with the results. \n",
    "    Parameters\n",
    "    ----------\n",
    "    wbo_file : str\n",
    "        path to xTB wbo output file\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list with Wiberg bond orders (only covalent bonds)\n",
    "    \"\"\"\n",
    "    with open(wbo_file, \"r\") as f:\n",
    "        lines = [elem.rstrip(\"\\n\") for elem in f.readlines()]\n",
    "    tmp = [\n",
    "        [int(line[:12]) - 1, int(line[12:24]) - 1, float(line[24:])] for line in lines\n",
    "    ]\n",
    "    wbo_dict = {f\"{min((a1, a2))}-{max((a1, a2))}\": wbo for a1, a2, wbo in tmp}\n",
    "    return wbo_dict\n",
    "\n",
    "\n",
    "def run_xtb_calc(mol, opt=False, return_optmol=False, method=\"gfn2\"):\n",
    "    \"\"\"Runs xTB single-point calculation with optional geometry optimization.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mol : pybel molecule object\n",
    "        assumes hydrogens are present\n",
    "    opt : bool, optional\n",
    "        Whether to optimize the geometry, by default False\n",
    "    return_optmol : bool, optional\n",
    "        Whether to return the optimized molecule, in case optimization was requested, by default False\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Molecular properties as computed by GFN2-xTB (formation energy, HOMO/LUMO/gap energies, dipole, atomic charges)\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If xTB calculation yield a non-zero return code.\n",
    "    \"\"\"\n",
    "\n",
    "    if return_optmol and not opt:\n",
    "        LOGGER.info(\n",
    "            \"Can't have `return_optmol` set to True with `opt` set to False. Setting the latter to True now.\"\n",
    "        )\n",
    "        opt = True\n",
    "\n",
    "    xtb_command = \"--opt\" if opt else \"\"\n",
    "    method = \"--\" + method\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    logfile = os.path.join(temp_dir, \"xtb.log\")\n",
    "    xtb_out = os.path.join(temp_dir, \"xtbout.json\")\n",
    "    xtb_wbo = os.path.join(temp_dir, \"wbo\")\n",
    "\n",
    "    sdf_path = os.path.join(temp_dir, \"mol.sdf\")\n",
    "    mol.ToSDFFile(sdf_path)\n",
    "    \n",
    "    with open(logfile, \"w\") as f:\n",
    "        xtb_run = subprocess.run(\n",
    "            [\n",
    "                XTB_BINARY,\n",
    "                sdf_path,\n",
    "                xtb_command,\n",
    "                method,\n",
    "                \"--input\",\n",
    "                XTB_INPUT_FILE,\n",
    "                \"--chrg\",\n",
    "                str(mol.GetFormalCharge()),\n",
    "                \"--wbo\",\n",
    "                \"--json\",\n",
    "                \"true\",\n",
    "            ],\n",
    "            stdout=f,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            cwd=temp_dir,\n",
    "            env=XTB_ENV,\n",
    "        )\n",
    "    if xtb_run.returncode != 0:\n",
    "        error_out = os.path.join(temp_dir, \"xtb.log\")\n",
    "        raise ValueError(f\"xTB calculation failed. See {error_out} for details.\")\n",
    "\n",
    "    else:\n",
    "        if method == \"--gff\":\n",
    "            opt_mol = RDKitMol.FromFile(os.path.join(temp_dir, \"xtbopt.sdf\"))[0]\n",
    "            rmtree(temp_dir)\n",
    "            return (None, opt_mol) if return_optmol else None\n",
    "        props = read_xtb_json(xtb_out, mol)\n",
    "        if return_optmol:\n",
    "            opt_mol = RDKitMol.FromFile(os.path.join(temp_dir, \"xtbopt.sdf\"))[0]\n",
    "            # opt_mol = next(pybel.readfile(\"sdf\", os.path.join(temp_dir, \"xtbopt.sdf\")))\n",
    "        props.update({\"wbo\": get_wbo(xtb_wbo)})\n",
    "        rmtree(temp_dir)\n",
    "        return (props, opt_mol) if return_optmol else props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead509b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GeoMol] *",
   "language": "python",
   "name": "conda-env-GeoMol-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
